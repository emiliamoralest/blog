---
title: "Day 3: Nextflow, nf-core and AI in bioinformatics"
description: "Introduction to workflow managers and AI talks"
author: "Emilia Morales"
date: "2025-10-08"
categories: [post]
image: "images/chat.jpeg"
---

### Information to remember  
**Workflow managers**

- Workflow managers, such as Nextflow and Snakemake, help us simplify several steps of a pipeline by 'wrapping' them up and running them automatically. 
- This way, we only have to launch the pipeline with one command and the proper parameters, and it runs all the necessary steps until the result we wish. It avoids us having one script for every step we want to run.
- They can run containers to eliminate package installation conflicts.
- They make the processes more reproducible.
- In Nextflow, we assign as *channel* our information, such as data, input, output, etc. Each actual script is called *process* and can be written in any language. We assign our *workflow scope* by defining the order of the processes and the interaction with eachother.

![Nextflow in a nutshell](images/nextflow.png){width=70% fig-align="center"}

- Nextflow is a Domain Specific Language (DSL) implemented as an extension of the Groovy programming language. This means that Nextflow can run any Groovy and Java code.
- If the pipeline fails at some point, the execution can be resumed easily from the spot since results are cached in the `work` folder. Once we're done running the pipeline we should delete this, as can take up a lot of disk space.
- Processes run independently from each other. So processes that are set to run simultaneously will run in no particular order.
- Usually, the content of a channel is consumed only once.
- In a Nextflow script, first we need to define our parameters (data) and channels (actions). Then the codes for each process. And finally the workflow scope, where we indicate what we want to be done with our parameters and channels. (The order doesn't have to be like this strictly.)
- We also need a `nextflow.config` file where we can choose *slurm* as the executor, how many cpus to use and the maximum run time. We can also set individual choices for each process.

**nf-core**

- nf-core is a community built around Nextflow. There we can find several bioinformatics pipelines developed by volunteers with Nextflow.
- nf-core also provides processes as *modules*, if the whole pipeline is not required.
- We can access their pipelines [here](https://nf-co.re/pipelines/>). And the modules [here](https://nf-co.re/modules/).
- In order to run an nf-core pipeline, we have to go its website and click on *Launch version X*, where we will be taken to another page to enter parameters about our samples and process, and we will get a JSON file necessary for our run. 
- We will also need an hpc2n.config file with our project ID information.
- **Important:** nf-core configs ready for UPPMAX <https://nf-co.re/configs/uppmax/>

> **Note:** This material was taken from the course's webpage.

---

### What we did today  
On the third day of the course, we tested Netflow and nf-core. For Nextflow, first, we copied the training material from the course. Then we run a script that did some basic commands, like breaking our input text into chunks of 6 characters, and capitalizing the letters or turning them backwards. For this, we learnt how the structure of a nextflow file should be and how to manipulate each part. Then we ran the script using Pixi also. We learnt what each nextflow output file shows and why. Finally, we learnt how to clean up the working directory Nextflow generates when running our commands. 
Then, we tested an RNA sequencing analysis pipeline that is established in Nextflow. In the nextflow.config script we can set different parameters to be used in the further scripts, like for it to be executed with slurm, the default time limit for all processes and the project account. We then tried to run the first script that creates a transcriptome index file, using the tool salmon as a container. We couldn't finish running this, as our cluster ran out of resources allocated for us.
We learnt the theory behind nf-core, but couldn't test it either because of the resources. 

Afterwards, we had a discussion about the use of AI in bioinformatics. It was interesting to learn that most Swedish universities allow the use of AI in official students' works as long as it is disclosed. I think this is fair, as AI is widely integrated in our daily lives by now, and it's not going anywhere. So we should learn to use it properly to our advantage instead of banning it.